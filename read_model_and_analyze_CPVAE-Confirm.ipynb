{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "from sklearn import tree\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_celeba(data_dir, restricted_degree, label_type, print_ratio=False):\n",
    "    \"\"\"Returns CelebA as (train_data, train_labels, test_data, test_labels)\n",
    "\n",
    "        Shapes are (162770, 64, 64, 3), (162770, 2), (19962, 64, 64, 3), (19962, 10)\n",
    "        Data is in [0,1] and labels are one-hot\n",
    "\n",
    "        Arg:\n",
    "          restricted_degree: only keep the instances with at least d selected attributes\n",
    "    \"\"\"\n",
    "    train_data = np.load(os.path.join(data_dir, 'celeba_train_imgs.npy'))\n",
    "    test_data = np.load(os.path.join(data_dir, 'celeba_test_imgs.npy'))\n",
    "\n",
    "    info_pak = np.load(os.path.join(data_dir, 'celeba_attr.npz'))\n",
    "    train_idxs = info_pak['train_idxs']\n",
    "    val_idxs = info_pak['val_idxs']\n",
    "    test_idxs = info_pak['test_idxs']\n",
    "    attribute_names = info_pak['attribute_names']\n",
    "    attributes = info_pak['attributes']\n",
    "    male_attr_idx = 20\n",
    "\n",
    "    def get_label(data, idxs):\n",
    "        label = attributes[idxs]\n",
    "\n",
    "        if label_type == 'gender':\n",
    "            label = 1-label[:, male_attr_idx].reshape([-1, 1])\n",
    "            label = np.append(label, 1 - label, 1)\n",
    "        elif label_type == 'subattr':\n",
    "            pass\n",
    "        return data, label\n",
    "\n",
    "    train_data, train_label = get_label(train_data, train_idxs)\n",
    "    test_data, test_label = get_label(test_data, test_idxs)\n",
    "\n",
    "    if print_ratio:\n",
    "        print('\\nCelebA restricted degree: {}'.format(restricted_degree))\n",
    "        train_ratio = sum(train_label[:, 1]) / train_label.shape[0]\n",
    "        test_ratio = sum(test_label[:, 1]) / test_label.shape[0]\n",
    "        print('Training set - Male: {:.2f}% ({}/{}), Not male: {:.2f}%'.format(train_ratio * 100,\n",
    "                                                                               sum(train_label[:, 1]),\n",
    "                                                                               train_label.shape[0],\n",
    "                                                                               100 - train_ratio * 100))\n",
    "        print('Testing set - Male: {:.2f}% ({}/{}), Not male: {:.2f}%'.format(test_ratio * 100,\n",
    "                                                                              sum(test_label[:, 1]),\n",
    "                                                                              test_label.shape[0],\n",
    "                                                                              100 - test_ratio * 100))\n",
    "\n",
    "    return train_data, train_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_labels = load_celeba(\n",
    "        'H:\\\\CodeRange\\\\CelebA\\\\npy\\\\', restricted_degree=0, print_ratio=False, label_type='subattr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_names = np.load('H:\\\\CodeRange\\\\CelebA\\\\npy\\\\celeba_attr.npz')['attribute_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-9e098447d9b4>:4: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From H:\\Miniconda\\envs\\sounds-deep\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/SkewRank06_High_Cheekbones/saved_model\\variables\\variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Miniconda\\envs\\sounds-deep\\lib\\site-packages\\sklearn\\base.py:253: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "model=tf.saved_model.loader.load(session, [tf.saved_model.tag_constants.SERVING], './saved_model/SkewRank06_High_Cheekbones/saved_model')\n",
    "with open('./saved_model/SkewRank06_High_Cheekbones/saved_model/decision_tree.pkl', 'rb') as dt_file:\n",
    "    decision_tree = pickle.load(dt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x                   , data_ph:0\n",
      "latent_var          , vae_1/MultivariateNormalDiag/sample/affine_linear_operator/forward/add:0\n",
      "output              , vae_1/batch_apply/Reshape_1:0\n"
     ]
    }
   ],
   "source": [
    "def get_variables(model_meta):\n",
    "    graph = tf.get_default_graph()\n",
    "    sig_vars = copy.deepcopy(model_meta.signature_def['serving_default'])\n",
    "    sig_inputs = sig_vars.inputs\n",
    "    sig_outputs = sig_vars.outputs\n",
    "    output = dict()\n",
    "    for k in sig_inputs.keys():\n",
    "        print('{:20}, {}'.format(k,sig_inputs[k].name))\n",
    "        output[k] = graph.get_tensor_by_name(sig_inputs[k].name)\n",
    "    for k in sig_outputs.keys():\n",
    "        print('{:20}, {}'.format(k,sig_outputs[k].name))\n",
    "        output[k] = graph.get_tensor_by_name(sig_outputs[k].name)\n",
    "    return output\n",
    "\n",
    "tensors = get_variables(model)\n",
    "\n",
    "t_x = tensors['x']\n",
    "t_latent_var = tensors['latent_var']\n",
    "t_output = tensors['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 5086/5086 [01:29<00:00, 56.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 623/623 [00:10<00:00, 57.99it/s]\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 32\n",
    "\n",
    "def get_latent_var_list(data):\n",
    "    test_data = data\n",
    "    test_data_len = test_data.shape[0]\n",
    "    epoch_num = test_data_len // epoch_size\n",
    "    # epoch_num = 60\n",
    "    instance_num = epoch_num * epoch_size\n",
    "\n",
    "    latent_var = []\n",
    "    for i in tqdm(range(epoch_num)):\n",
    "        epoch_beg = i*epoch_size\n",
    "        epoch_end = (i+1)*epoch_size\n",
    "        epoch_input = test_data[epoch_beg:epoch_end].astype('float32') / 255.0\n",
    "    #     print(epoch_beg, epoch_end)\n",
    "        outputs = session.run([t_output, t_latent_var], \n",
    "                              feed_dict={t_x:epoch_input})\n",
    "        latent_var.append(outputs[1])\n",
    "    return latent_var\n",
    "\n",
    "train_latent_var_lists = get_latent_var_list(train_data)\n",
    "test_latent_var_lists = get_latent_var_list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_latent_var_lists = np.array(train_latent_var_lists).reshape([-1, 50])\n",
    "test_latent_var_lists = np.array(test_latent_var_lists).reshape([-1, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8281500802568218"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_label = 1-test_labels[:19936, 19]\n",
    "tr_label = 1-train_labels[:162752, 19]\n",
    "decision_tree.score(test_latent_var_lists, te_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_latent_var_lists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_names = np.load('./gender-classification/data/toy_celeba/celeba_attr.npz')['attribute_names']\n",
    "for i,ac in enumerate(accu):\n",
    "    print('{:4}: {:20}, {:.4f}'.format(i, attributes_names[i], ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "idx = 20\n",
    "\n",
    "outputs = session.run([t_output, t_latent_var], feed_dict={t_x:train_data[:32]})\n",
    "\n",
    "plt.imshow(train_data[idx])\n",
    "plt.show()\n",
    "\n",
    "z = outputs[1]\n",
    "y = outputs[0]\n",
    "temp = y[0, idx, :]\n",
    "plt.imshow(temp)\n",
    "plt.show()\n",
    "\n",
    "print('Male:', train_latent_labels[idx][20])\n",
    "print('Mustache:', train_latent_labels[idx][22])\n",
    "print('No_Beard:', train_latent_labels[idx][24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=decision_tree.decision_path([z[0][idx]])\n",
    "for i,x in enumerate(z[0][idx]):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(\n",
    "        decision_tree,\n",
    "        out_file='./tree.dot',\n",
    "        class_names=['negative', 'positive'],\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        proportion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info_to_node_label(in_filename, out_filename, node_id, info):\n",
    "    with open(in_filename) as f:\n",
    "        linelist = f.readlines()\n",
    "    for i,s in enumerate(linelist):\n",
    "        if s.startswith('{} [label='.format(node_id)):\n",
    "            idx = s.find('\", fillcolor=')\n",
    "            s = s[:idx] + \"\\\\n\" + info + s[idx:]\n",
    "            linelist[i] = s\n",
    "            break\n",
    "    with open(out_filename, \"w+\") as f:\n",
    "        for x in linelist:\n",
    "            f.write(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(attributes_names):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
